{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twin Delayed Deep Deterministic Policy Gradients (TD3) \n",
    "\n",
    "This notebook presents the [Twin Delayed Deep Deterministic Policy Gradients (a.k.a., TD3)](https://arxiv.org/pdf/1802.09477.pdf), which is an upgraded version of [Deep Deterministic Policy Gradients (DDPG)](https://arxiv.org/pdf/1509.02971.pdf). The code is from [this repository](https://github.com/sfujim/TD3/blob/master/TD3.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mosesnah/Documents/projects/machine-learning-tutorial/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gym\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim         as optim\n",
    "import numpy               as np\n",
    "import matplotlib.pyplot   as plt\n",
    "import moviepy.editor      as mpy\n",
    "\n",
    "# Check whether GPU computation (i.e., CUDA) is available.\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available( ) else \"cpu\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay Buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer( object ):\n",
    "\n",
    "    def __init__( self, n_state, n_action, max_size = 100000 ):\n",
    "\n",
    "        # Save the dimension of state, dimension of action and the maximum size of the replay buffer\n",
    "        self.n_state  = n_state\n",
    "        self.n_action = n_action\n",
    "        self.max_size = max_size\n",
    "\n",
    "        # Defining the current size of the replay buffer, just to make the sampling easy. \n",
    "        self.current_size = 0\n",
    "\n",
    "        # Defining the Index Pointer (ptr) of the replaybuffer. \n",
    "        # This is required for \"adding\" the experiences on the replaybuffer. \n",
    "        self.idx_ptr      = 0\n",
    "\n",
    "        # Defining the 2D arrays of the ReplayBuffer\n",
    "        # 2D array definition is necessary to forward the Neural Network\n",
    "        self.states      = np.zeros( ( max_size, n_state   ) )\n",
    "        self.actions     = np.zeros( ( max_size, n_action  ) )\n",
    "        self.rewards     = np.zeros( ( max_size, 1         ) )\n",
    "        self.next_states = np.zeros( ( max_size, n_state   ) )\n",
    "        self.is_done     = np.zeros( ( max_size, 1         ) )\n",
    "\n",
    "\n",
    "    def add( self, state, action, reward, next_state, is_done ):\n",
    "        \"\"\"\n",
    "            Adding a state-action-reward-next_state pair into the ReplayBuffer. \n",
    "        \"\"\"\n",
    "\n",
    "        self.states[      self.idx_ptr ] = state\n",
    "        self.actions[     self.idx_ptr ] = action\n",
    "        self.rewards[     self.idx_ptr ] = reward\n",
    "        self.next_states[ self.idx_ptr ] = next_state\n",
    "        self.is_done[     self.idx_ptr ] = is_done\n",
    "\n",
    "        # Update our index pointer. Note that the \"oldest\" experiences are overwritten.\n",
    "        self.idx_ptr = ( self.idx_ptr + 1 ) % self.max_size\n",
    "\n",
    "        # Update the current size of the replay buffer\n",
    "        self.current_size = min( self.current_size + 1, self.max_size )\n",
    "\n",
    "    def sample( self, n_batch_size ):\n",
    "        \"\"\"\n",
    "            Collect \"n_batch_size\" samples from the replay buffer and return it as a batch.\n",
    "        \"\"\"\n",
    "        idx = np.random.randint( 0, self.current_size, size = n_batch_size )\n",
    "\n",
    "        # Returning the 2D numpy array as a 2D torch array.\n",
    "\n",
    "        return ( \n",
    "            torch.FloatTensor(      self.states[ idx ]  ).to( device ) ,\n",
    "            torch.FloatTensor(     self.actions[ idx ]  ).to( device ) , \n",
    "            torch.FloatTensor(     self.rewards[ idx ]  ).to( device ) ,\n",
    "            torch.FloatTensor( self.next_states[ idx ]  ).to( device ) ,\n",
    "            torch.FloatTensor(     self.is_done[ idx ]  ).to( device )   \n",
    "        )\n",
    "\n",
    "\n",
    "    def reset( self ):\n",
    "        \"\"\"\n",
    "            Reset all the replay buffers to zeros\n",
    "        \"\"\"\n",
    "        self.states      = np.zeros( ( self.max_size, self.n_state   ) )\n",
    "        self.actions     = np.zeros( ( self.max_size, self.n_action  ) )\n",
    "        self.rewards     = np.zeros( ( self.max_size, 1              ) )\n",
    "        self.next_states = np.zeros( ( self.max_size, self.n_state   ) )\n",
    "        self.is_done     = np.zeros( ( self.max_size, 1              ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor and Critic Networks\n",
    "As with the DDPG algorithm, TD3 also has two separate Actor and Critic Networks. The only difference is the critic of TD3 method has two separate neural networks to get two Q values, $Q_1$ and $Q_2$. The TD3 algorithm is inspired from Double Q-learning, which is the reason why we have $Q_1$ and $Q_2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor( nn.Module ):\n",
    "    def __init__( self, n_state: int, n_action: int, n_hidden: int = 256, max_action: float = 1.0 ):\n",
    "\n",
    "        # Class inheritance. \n",
    "        super( Actor, self ).__init__( )\n",
    "\n",
    "        # Save the maximum action value \n",
    "        assert max_action >= 0\n",
    "        self.max_action = max_action\n",
    "\n",
    "        # First Layer, changes array  with size N x ( n_state  ) to N x ( n_hidden )\n",
    "        self.l1 = nn.Linear(  n_state, n_hidden )\n",
    "\n",
    "        # Second Layer, changes array with size N x ( n_hidden ) to N x ( n_hidden )\n",
    "        self.l2 = nn.Linear( n_hidden, n_hidden )\n",
    "\n",
    "        # Third Layer, changes array  with size N x ( n_hidden ) to N x ( n_action )\n",
    "        self.l3 = nn.Linear( n_hidden, n_action )\n",
    "        \n",
    "    def forward( self, state ):\n",
    "        \n",
    "        # Applying Rectified Linear Unit (ReLU) to x\n",
    "        x = F.relu( self.l1( state ) )\n",
    "\n",
    "        # Applying Rectified Linear Unit (ReLU) to x\n",
    "        x = F.relu( self.l2( x ) )\n",
    "\n",
    "        # Applying to tanh, which ranges the value from -1 to +1\n",
    "        x = torch.tanh( self.l3( x ) ) \n",
    "\n",
    "        # Since the x value is from -1 to +1, we change the range to -max_action to +max_action.\n",
    "        return x * self.max_action\n",
    "\n",
    "class Critic( nn.Module ):\n",
    "    \"\"\"\n",
    "        Learning the Q(s,a) function, which is the \"Quality\" function. Hence, input is a concatenation of state, action and the output is a scalar. \n",
    "    \"\"\"\n",
    "    def __init__( self, n_state, n_action, n_hidden: int = 256 ):\n",
    "\n",
    "        # Class inheritance. \n",
    "        super( Critic, self ).__init__()\n",
    "\n",
    "\n",
    "        # ================================================================================ #\n",
    "        # ================================= First Q-Network ============================== #\n",
    "        # ================================================================================ #\n",
    "        # First Layer, changes array with size N x ( n_state + n_action ) to N x ( n_hidden )\n",
    "        self.l1 = nn.Linear( n_state + n_action, n_hidden )\n",
    "\n",
    "        # Second Layer, changes array with size N x ( n_hidden ) to N x ( n_hidden )\n",
    "        self.l2 = nn.Linear( n_hidden, n_hidden )\n",
    "\n",
    "        # Third Layer, changes array with size N x ( n_hidden ) to N x ( 1 ), since Q is a scalar function. \n",
    "        self.l3 = nn.Linear( n_hidden, 1 )\n",
    "\n",
    "        # ================================================================================ #\n",
    "        # ================================ Second Q-Network ============================== #\n",
    "        # ================================================================================ #\n",
    "        # First Layer, changes array with size N x ( n_state + n_action ) to N x ( n_hidden )\n",
    "        self.l4 = nn.Linear( n_state + n_action, n_hidden )\n",
    "\n",
    "        # Second Layer, changes array with size N x ( n_hidden ) to N x ( n_hidden )\n",
    "        self.l5 = nn.Linear( n_hidden, n_hidden )\n",
    "\n",
    "        # Third Layer, changes array with size N x ( n_hidden ) to N x ( 1 ), since Q is a scalar function. \n",
    "        self.l6 = nn.Linear( n_hidden, 1 )\n",
    "\n",
    "        # Note that the first and second Q-networks has exactly the same structure. The parameters are only difference. \n",
    "    \n",
    "    def forward( self, state, action ):\n",
    "\n",
    "        # Concatenation of state and action vector.\n",
    "        # The state  is assumed to be a 2D array with size N x n_s, where N is the number of samples\n",
    "        # The action is assumed to be a 2D array with size N x n_a, where N is the number of samples\n",
    "        # As a result of torch.cat( [ state, action ] along axis 1, ), we have size N x ( n_s + n_a ), and the dim = 0 must have the same size\n",
    "        x = torch.cat( [ state, action ], dim = 1 )\n",
    "\n",
    "\n",
    "        # ================================================================================ #\n",
    "        # =========================== Calculating Q1 and Q2 ============================== #\n",
    "        # ================================================================================ #\n",
    "\n",
    "        # Applying Rectified Linear Unit (ReLU) to x\n",
    "        q1 = F.relu( self.l1( x ) )\n",
    "        q2 = F.relu( self.l4( x ) )\n",
    "\n",
    "        # Applying Rectified Linear Unit (ReLU) to x\n",
    "        q1 = F.relu( self.l2( q1 ) )\n",
    "        q2 = F.relu( self.l5( q2 ) )\n",
    "\n",
    "        # A simple Ax + b combination \n",
    "        q1 = self.l3( q1 )\n",
    "        q2 = self.l6( q2 )\n",
    "\n",
    "        # The output is a N x 1 array. \n",
    "        return q1, q2\n",
    "\n",
    "    def Q1( self, state, action ):\n",
    "        x = torch.cat( [ state, action ], dim = 1 )\n",
    "\n",
    "        # Applying Rectified Linear Unit (ReLU) to x\n",
    "        q1 = F.relu( self.l1( x ) )\n",
    "        q1 = F.relu( self.l2( q1 ) )\n",
    "        q1 = self.l3( q1 )\n",
    "\n",
    "        return q1\n",
    "\n",
    "\n",
    "\n",
    "class TD3( object ):\n",
    "\n",
    "    def __init__( self, n_state, n_action, max_action, gamma = 0.99, tau = 0.005, policy_noise = 0.2, noise_clip = 0.5, policy_freq = 2 ):\n",
    "\n",
    "        self.actor            = Actor( n_state, n_action, max_action = max_action ).to( device )\n",
    "        self.actor_target     = copy.deepcopy( self.actor )\n",
    "        self.actor_optimizer  = torch.optim.Adam( self.actor.parameters( ) , lr = 1e-4 )\n",
    "\n",
    "        self.critic           = Critic( n_state, n_action ).to( device )\n",
    "        self.critic_target    = copy.deepcopy( self.critic )\n",
    "        self.critic_optimizer = torch.optim.Adam( self.critic.parameters( ), lr = 1e-3 )\n",
    "\n",
    "        self.max_action = max_action\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.tau   = tau \n",
    "\n",
    "        self.policy_noise = policy_noise\n",
    "        self.noise_clip   = noise_clip\n",
    "        self.policy_freq  = policy_freq\n",
    "        \n",
    "        self.total_it = 0 \n",
    "\n",
    "    def get_action( self, state ):\n",
    "\n",
    "        # Conduct the a = mu(s), where mu is a \"deterministic function\"\n",
    "        # Unsqueeze makes an 1 x n_s array of state. \n",
    "        state  = torch.from_numpy( state ).float( ).unsqueeze( 0 ).to( device )\n",
    "\n",
    "        # Returns an 1 x n_a array of state\n",
    "        # forward method can be omitted\n",
    "        action = self.actor( state )\n",
    "\n",
    "        # Change action from Torch to Numpy.\n",
    "        # Since n_a is 1 for this case, action is simply an 1x1 array.\n",
    "        # Hence, flattening the data. \n",
    "        action = action.cpu( ).data.numpy( ).flatten( )\n",
    "\n",
    "        return action\n",
    "    \n",
    "    def update( self, replay_buffer, batch_size: int = 256 ):\n",
    "\n",
    "        self.total_it += 1\n",
    "        state, action, reward, next_state, is_done = replay_buffer.sample( batch_size )\n",
    "\n",
    "        with torch.no_grad( ):\n",
    "            noise       = ( torch.randn_like( action ) * self.policy_noise  ).clamp( -self.noise_clip, self.noise_clip )\n",
    "            next_action = ( self.actor_target( next_state ) + noise ).clamp( -self.max_action, self.max_action )\n",
    "\n",
    "            target_Q1, target_Q2 = self.critic_target( next_state, next_action )\n",
    "            target_Q = torch.min( target_Q1, target_Q2 )\n",
    "            target_Q = reward + (  ( 1. - is_done ) * self.gamma * target_Q )#.detach( )\n",
    "\n",
    "\t\t# Get current Q estimates\n",
    "        current_Q1, current_Q2 = self.critic( state, action )\n",
    "\n",
    "\t\t# Compute critic loss\n",
    "        critic_loss = F.mse_loss(current_Q1, target_Q) + F.mse_loss(current_Q2, target_Q)\n",
    "\n",
    "\t\t# Optimize the critic\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "\t\t# Delayed policy updates\n",
    "        if self.total_it % self.policy_freq == 0:\n",
    "\n",
    "\t\t\t# Compute actor losse\n",
    "            actor_loss = -self.critic.Q1( state, self.actor( state ) ).mean()\n",
    "\t\t\t\n",
    "\t\t\t# Optimize the actor \n",
    "            self.actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "\n",
    "\t\t\t# Update the frozen target models\n",
    "            for target_param, param in zip( self.critic_target.parameters( ), self.critic.parameters( ) ):\n",
    "                target_param.data.copy_( self.tau * param.data + ( 1 - self.tau ) * target_param.data )\n",
    "                \n",
    "            for target_param, param in zip( self.actor_target.parameters( ) ,  self.actor.parameters( ) ):\n",
    "                target_param.data.copy_( self.tau * param.data + ( 1 - self.tau ) * target_param.data )\n",
    "\n",
    "\n",
    "    def save( self, filename ):\n",
    "        \n",
    "        torch.save( self.critic.state_dict( )           , filename + \"_critic\"              )\n",
    "        torch.save( self.critic_optimizer.state_dict( ) , filename + \"_critic_optimizer\"    )\n",
    "        \n",
    "        torch.save( self.actor.state_dict( )            , filename + \"_actor\"               )\n",
    "        torch.save( self.actor_optimizer.state_dict( )  , filename + \"_actor_optimizer\"     )\n",
    "\n",
    "\n",
    "    def load( self, filename ):\n",
    "\n",
    "        # Load Critic\n",
    "        self.critic.load_state_dict(            torch.load( filename + \"_critic\"           )  )\n",
    "        self.critic_optimizer.load_state_dict(  torch.load( filename + \"_critic_optimizer\" )  )\n",
    "        self.critic_target = copy.deepcopy( self.critic )\n",
    "\n",
    "        # Load Actor\n",
    "        self.actor.load_state_dict(             torch.load( filename + \"_actor\"            )  )\n",
    "        self.actor_optimizer.load_state_dict(   torch.load( filename + \"_actor_optimizer\"  )  )\n",
    "        self.actor_target = copy.deepcopy( self.actor )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0, reward: -1060.9, average_reward: -1060.8965981419828 \n",
      "episode: 1, reward: -1266.81, average_reward: -1163.851787087735 \n",
      "episode: 2, reward: -1119.42, average_reward: -1149.042556829702 \n",
      "episode: 3, reward: -1617.23, average_reward: -1266.0900278376178 \n",
      "episode: 4, reward: -1657.32, average_reward: -1344.3353398362765 \n",
      "episode: 5, reward: -1693.05, average_reward: -1402.4551019636995 \n",
      "episode: 6, reward: -1661.87, average_reward: -1439.5147241865955 \n",
      "episode: 7, reward: -1652.24, average_reward: -1466.104898909727 \n",
      "episode: 8, reward: -1634.53, average_reward: -1484.819067235211 \n",
      "episode: 9, reward: -1595.83, average_reward: -1495.9203691027753 \n",
      "episode: 10, reward: -1697.29, average_reward: -1559.560014564065 \n",
      "episode: 11, reward: -1510.33, average_reward: -1583.912381946961 \n",
      "episode: 12, reward: -1303.28, average_reward: -1602.298213824563 \n",
      "episode: 13, reward: -1415.23, average_reward: -1582.0984069592641 \n",
      "episode: 14, reward: -1241.15, average_reward: -1540.4815400594355 \n",
      "episode: 15, reward: -1237.73, average_reward: -1494.9489489322693 \n",
      "episode: 16, reward: -1319.8, average_reward: -1460.7415462224733 \n",
      "episode: 17, reward: -1350.84, average_reward: -1430.6014581816721 \n",
      "episode: 18, reward: -1276.47, average_reward: -1394.7952473901178 \n",
      "episode: 19, reward: -1395.87, average_reward: -1374.799317190344 \n",
      "episode: 20, reward: -1435.23, average_reward: -1348.5931282437998 \n",
      "episode: 21, reward: -1511.73, average_reward: -1348.7326244034589 \n",
      "episode: 22, reward: -1497.43, average_reward: -1368.1471261460654 \n",
      "episode: 23, reward: -1318.83, average_reward: -1358.506894294737 \n",
      "episode: 24, reward: -1340.49, average_reward: -1368.4411034814793 \n",
      "episode: 25, reward: -1007.98, average_reward: -1345.4660724998198 \n",
      "episode: 26, reward: -1056.17, average_reward: -1319.1027920874772 \n",
      "episode: 27, reward: -1252.69, average_reward: -1309.2881328940518 \n",
      "episode: 28, reward: -1498.25, average_reward: -1331.4660364996732 \n",
      "episode: 29, reward: -907.82, average_reward: -1282.6608852852585 \n",
      "episode: 30, reward: -1051.45, average_reward: -1244.2829612642774 \n",
      "episode: 31, reward: -690.44, average_reward: -1162.1541968605575 \n",
      "episode: 32, reward: -641.75, average_reward: -1076.5860471284598 \n",
      "episode: 33, reward: -774.04, average_reward: -1022.1070155366937 \n",
      "episode: 34, reward: -513.53, average_reward: -939.4107046507015 \n",
      "episode: 35, reward: -751.94, average_reward: -913.807420197177 \n",
      "episode: 36, reward: -1492.41, average_reward: -957.4318210837652 \n",
      "episode: 37, reward: -660.31, average_reward: -898.1942832199138 \n",
      "episode: 38, reward: -638.45, average_reward: -812.2143871133047 \n",
      "episode: 39, reward: -650.93, average_reward: -786.5256783352671 \n",
      "episode: 40, reward: -789.69, average_reward: -760.3496592164045 \n",
      "episode: 41, reward: -932.85, average_reward: -784.5913407782607 \n",
      "episode: 42, reward: -637.38, average_reward: -784.1546787612629 \n",
      "episode: 43, reward: -666.03, average_reward: -773.3539381670028 \n",
      "episode: 44, reward: -1492.74, average_reward: -871.2754439344286 \n",
      "episode: 45, reward: -749.88, average_reward: -871.0693647621936 \n",
      "episode: 46, reward: -829.45, average_reward: -804.7735293468502 \n",
      "episode: 47, reward: -747.78, average_reward: -813.5202465588654 \n",
      "episode: 48, reward: -672.05, average_reward: -816.8801565749916 \n",
      "episode: 49, reward: -781.16, average_reward: -829.9025999172236 \n",
      "episode: 50, reward: -1514.67, average_reward: -902.400282545393 \n",
      "episode: 51, reward: -644.59, average_reward: -873.5739484974436 \n",
      "episode: 52, reward: -1495.84, average_reward: -959.420220823492 \n",
      "episode: 53, reward: -637.53, average_reward: -956.5695239793398 \n",
      "episode: 54, reward: -525.6, average_reward: -859.8556903735595 \n",
      "episode: 55, reward: -1493.6, average_reward: -934.227139015594 \n",
      "episode: 56, reward: -514.18, average_reward: -902.7003738188671 \n",
      "episode: 57, reward: -527.01, average_reward: -880.6237821406667 \n",
      "episode: 58, reward: -667.92, average_reward: -880.210588152755 \n",
      "episode: 59, reward: -385.02, average_reward: -840.5968627942979 \n",
      "episode: 60, reward: -384.53, average_reward: -727.5830840247755 \n",
      "episode: 61, reward: -260.3, average_reward: -689.1542395641701 \n",
      "episode: 62, reward: -129.24, average_reward: -552.4939222303962 \n",
      "episode: 63, reward: -403.56, average_reward: -529.0971035363524 \n",
      "episode: 64, reward: -1133.96, average_reward: -589.9329912550647 \n",
      "episode: 65, reward: -957.28, average_reward: -536.3006656924756 \n",
      "episode: 66, reward: -391.69, average_reward: -524.051615869149 \n",
      "episode: 67, reward: -1045.29, average_reward: -575.8793669295417 \n",
      "episode: 68, reward: -4.57, average_reward: -509.5444664997344 \n",
      "episode: 69, reward: -265.37, average_reward: -497.57919272589027 \n",
      "episode: 70, reward: -124.17, average_reward: -471.54321100610844 \n",
      "episode: 71, reward: -242.93, average_reward: -469.8060107724794 \n",
      "episode: 72, reward: -255.42, average_reward: -482.424051290885 \n",
      "episode: 73, reward: -237.59, average_reward: -465.82757614433075 \n",
      "episode: 74, reward: -773.3, average_reward: -429.7614949659971 \n",
      "episode: 75, reward: -400.46, average_reward: -374.0802644630574 \n",
      "episode: 76, reward: -1.06, average_reward: -335.01661212923324 \n",
      "episode: 77, reward: -244.48, average_reward: -254.93502035138528 \n",
      "episode: 78, reward: -251.52, average_reward: -279.62998949408643 \n",
      "episode: 79, reward: -129.88, average_reward: -266.0814894852954 \n",
      "episode: 80, reward: -368.0, average_reward: -290.46410669990485 \n",
      "episode: 81, reward: -125.64, average_reward: -278.7347749493357 \n",
      "episode: 82, reward: -119.01, average_reward: -265.0935403223442 \n",
      "episode: 83, reward: -125.52, average_reward: -253.8858484603657 \n",
      "episode: 84, reward: -125.95, average_reward: -189.15114515148596 \n",
      "episode: 85, reward: -1.57, average_reward: -149.26142230647787 \n",
      "episode: 86, reward: -470.66, average_reward: -196.2217473780745 \n",
      "episode: 87, reward: -122.39, average_reward: -184.01276144933462 \n",
      "episode: 88, reward: -1.4, average_reward: -159.00134164040293 \n",
      "episode: 89, reward: -244.78, average_reward: -170.49052594027003 \n",
      "episode: 90, reward: -125.58, average_reward: -146.24854226076425 \n",
      "episode: 91, reward: -240.94, average_reward: -157.77884685823577 \n",
      "episode: 92, reward: -120.65, average_reward: -157.94313690850632 \n",
      "episode: 93, reward: -404.34, average_reward: -185.825718734376 \n",
      "episode: 94, reward: -128.36, average_reward: -186.06627707293933 \n",
      "episode: 95, reward: -235.91, average_reward: -209.5004727497929 \n",
      "episode: 96, reward: -368.09, average_reward: -199.24346205883094 \n",
      "episode: 97, reward: -370.84, average_reward: -224.0883704342421 \n",
      "episode: 98, reward: -2.87, average_reward: -224.23499278600448 \n",
      "episode: 99, reward: -243.53, average_reward: -224.11088966368567 \n",
      "episode: 100, reward: -123.05, average_reward: -223.8577021180378 \n",
      "episode: 101, reward: -124.31, average_reward: -212.1949686663091 \n",
      "episode: 102, reward: -249.03, average_reward: -225.03281756163938 \n",
      "episode: 103, reward: -3.51, average_reward: -184.94923512545984 \n",
      "episode: 104, reward: -128.38, average_reward: -184.95160286564183 \n",
      "episode: 105, reward: -124.34, average_reward: -173.7950326020644 \n",
      "episode: 106, reward: -3.91, average_reward: -137.37675841890638 \n",
      "episode: 107, reward: -344.76, average_reward: -134.76919503820622 \n",
      "episode: 108, reward: -237.48, average_reward: -158.23058337780006 \n",
      "episode: 109, reward: -4.02, average_reward: -134.27921968944025 \n",
      "episode: 110, reward: -128.56, average_reward: -134.83091497870367 \n",
      "episode: 111, reward: -123.96, average_reward: -134.7951726232737 \n",
      "episode: 112, reward: -126.16, average_reward: -122.50875982983919 \n",
      "episode: 113, reward: -123.35, average_reward: -134.4930955956154 \n",
      "episode: 114, reward: -382.88, average_reward: -159.94230231752806 \n",
      "episode: 115, reward: -233.57, average_reward: -170.86477104626226 \n",
      "episode: 116, reward: -121.84, average_reward: -182.65769768615624 \n",
      "episode: 117, reward: -361.48, average_reward: -184.33008540447625 \n",
      "episode: 118, reward: -375.72, average_reward: -198.15323499072719 \n",
      "episode: 119, reward: -1.56, average_reward: -197.90731011301682 \n",
      "episode: 120, reward: -127.67, average_reward: -197.81776110029233 \n",
      "episode: 121, reward: -357.35, average_reward: -221.15667724618189 \n",
      "episode: 122, reward: -243.8, average_reward: -232.92038285213053 \n",
      "episode: 123, reward: -239.35, average_reward: -244.52042347094434 \n",
      "episode: 124, reward: -347.74, average_reward: -241.00710285973224 \n",
      "episode: 125, reward: -127.6, average_reward: -230.4102975381573 \n",
      "episode: 126, reward: -123.87, average_reward: -230.61371528450263 \n",
      "episode: 127, reward: -255.53, average_reward: -220.01847888518768 \n",
      "episode: 128, reward: -425.02, average_reward: -224.94851420669266 \n",
      "episode: 129, reward: -129.04, average_reward: -237.69652427186983 \n",
      "episode: 130, reward: -1.97, average_reward: -225.1265205272917 \n",
      "episode: 131, reward: -121.49, average_reward: -201.54078857713935 \n",
      "episode: 132, reward: -356.94, average_reward: -212.8550559343064 \n",
      "episode: 133, reward: -228.49, average_reward: -211.76849676624585 \n",
      "episode: 134, reward: -118.62, average_reward: -188.855893376707 \n",
      "episode: 135, reward: -252.02, average_reward: -201.29827433003445 \n",
      "episode: 136, reward: -2.53, average_reward: -189.16387092203604 \n",
      "episode: 137, reward: -121.84, average_reward: -175.79501712657176 \n",
      "episode: 138, reward: -345.17, average_reward: -167.81034563362294 \n",
      "episode: 139, reward: -126.82, average_reward: -167.5886424858188 \n",
      "episode: 140, reward: -257.07, average_reward: -193.0988330071084 \n",
      "episode: 141, reward: -3.43, average_reward: -181.29316343871423 \n",
      "episode: 142, reward: -124.35, average_reward: -158.03378271105967 \n",
      "episode: 143, reward: -4.81, average_reward: -135.66658339659156 \n",
      "episode: 144, reward: -121.38, average_reward: -135.9424357085144 \n",
      "episode: 145, reward: -497.19, average_reward: -160.45943007145715 \n",
      "episode: 146, reward: -126.05, average_reward: -172.8114434673363 \n",
      "episode: 147, reward: -127.23, average_reward: -173.35033304589717 \n",
      "episode: 148, reward: -384.41, average_reward: -177.27400970216758 \n",
      "episode: 149, reward: -244.22, average_reward: -189.01362448907526 \n",
      "episode: 150, reward: -233.19, average_reward: -186.62532328586857 \n",
      "episode: 151, reward: -127.46, average_reward: -199.0277486113279 \n",
      "episode: 152, reward: -130.3, average_reward: -199.62309623749573 \n",
      "episode: 153, reward: -131.48, average_reward: -212.29002135770034 \n",
      "episode: 154, reward: -121.27, average_reward: -212.27975404965485 \n",
      "episode: 155, reward: -126.87, average_reward: -175.24743744393078 \n",
      "episode: 156, reward: -119.79, average_reward: -174.62162391735552 \n",
      "episode: 157, reward: -242.26, average_reward: -186.12450740868434 \n",
      "episode: 158, reward: -228.14, average_reward: -170.49814858106157 \n",
      "episode: 159, reward: -116.86, average_reward: -157.76214854785746 \n",
      "episode: 160, reward: -241.04, average_reward: -158.5474592092941 \n",
      "episode: 161, reward: -2.04, average_reward: -146.00599816437594 \n",
      "episode: 162, reward: -6.44, average_reward: -133.6200088921491 \n",
      "episode: 163, reward: -242.97, average_reward: -144.7690723207015 \n",
      "episode: 164, reward: -355.97, average_reward: -168.23881627556275 \n",
      "episode: 165, reward: -122.89, average_reward: -167.84086726636565 \n",
      "episode: 166, reward: -237.95, average_reward: -179.65687521055972 \n",
      "episode: 167, reward: -4.61, average_reward: -155.8918991867211 \n",
      "episode: 168, reward: -2.52, average_reward: -133.33002735831857 \n",
      "episode: 169, reward: -120.32, average_reward: -133.67628674619368 \n",
      "episode: 170, reward: -127.0, average_reward: -122.27211711645764 \n",
      "episode: 171, reward: -116.75, average_reward: -133.74310023835744 \n",
      "episode: 172, reward: -346.59, average_reward: -167.75751830121922 \n",
      "episode: 173, reward: -342.8, average_reward: -177.73970452376477 \n",
      "episode: 174, reward: -124.82, average_reward: -154.6246486672765 \n",
      "episode: 175, reward: -118.13, average_reward: -154.14878643599357 \n",
      "episode: 176, reward: -348.81, average_reward: -165.23525945630598 \n",
      "episode: 177, reward: -330.63, average_reward: -197.83723419539984 \n",
      "episode: 178, reward: -114.38, average_reward: -209.02287457506313 \n",
      "episode: 179, reward: -118.64, average_reward: -208.85407609275632 \n",
      "episode: 180, reward: -0.45, average_reward: -196.19925811273862 \n",
      "episode: 181, reward: -233.46, average_reward: -207.87065165706017 \n",
      "episode: 182, reward: -119.6, average_reward: -185.17168190651375 \n",
      "episode: 183, reward: -122.96, average_reward: -163.18851371887632 \n",
      "episode: 184, reward: -119.23, average_reward: -162.62914677967967 \n",
      "episode: 185, reward: -232.99, average_reward: -174.11480696574142 \n",
      "episode: 186, reward: -120.14, average_reward: -151.24744241268507 \n",
      "episode: 187, reward: -2.56, average_reward: -118.44003048371553 \n",
      "episode: 188, reward: -123.0, average_reward: -119.3024196216148 \n",
      "episode: 189, reward: -115.8, average_reward: -119.01909047830148 \n",
      "episode: 190, reward: -118.19, average_reward: -130.793351525317 \n",
      "episode: 191, reward: -118.13, average_reward: -119.26025276250398 \n",
      "episode: 192, reward: -126.88, average_reward: -119.98889550063438 \n",
      "episode: 193, reward: -126.17, average_reward: -120.30922150833608 \n",
      "episode: 194, reward: -233.8, average_reward: -131.76618333434823 \n",
      "episode: 195, reward: -2.3, average_reward: -108.69704467625823 \n",
      "episode: 196, reward: -232.12, average_reward: -119.89469491119772 \n",
      "episode: 197, reward: -334.99, average_reward: -153.1385574963776 \n",
      "episode: 198, reward: -124.11, average_reward: -153.24911379192133 \n",
      "episode: 199, reward: -119.3, average_reward: -153.59933735319595 \n",
      "episode: 200, reward: -119.47, average_reward: -153.72731666845579 \n",
      "episode: 201, reward: -124.21, average_reward: -154.3351579846558 \n",
      "episode: 202, reward: -0.54, average_reward: -141.700231841001 \n",
      "episode: 203, reward: -259.32, average_reward: -155.01555103973243 \n",
      "episode: 204, reward: -126.12, average_reward: -144.24844246934117 \n",
      "episode: 205, reward: -1.45, average_reward: -144.16343389371679 \n",
      "episode: 206, reward: -242.93, average_reward: -145.2445012512482 \n",
      "episode: 207, reward: -0.85, average_reward: -111.82979489044214 \n",
      "episode: 208, reward: -242.76, average_reward: -123.69466889481139 \n",
      "episode: 209, reward: -121.32, average_reward: -123.89616964717524 \n",
      "episode: 210, reward: -0.87, average_reward: -112.0357613385867 \n",
      "episode: 211, reward: -121.14, average_reward: -111.72828299701037 \n",
      "episode: 212, reward: -119.63, average_reward: -123.63728838341396 \n",
      "episode: 213, reward: -122.74, average_reward: -109.97924310341406 \n",
      "episode: 214, reward: -345.23, average_reward: -131.8897460897527 \n",
      "episode: 215, reward: -236.92, average_reward: -155.43681927578137 \n",
      "episode: 216, reward: -340.46, average_reward: -165.19009473807506 \n",
      "episode: 217, reward: -117.04, average_reward: -176.8088845471055 \n",
      "episode: 218, reward: -241.03, average_reward: -176.6357547982305 \n",
      "episode: 219, reward: -117.22, average_reward: -176.22563447322915 \n",
      "episode: 220, reward: -119.89, average_reward: -188.1274526472102 \n",
      "episode: 221, reward: -126.8, average_reward: -188.69349677124438 \n",
      "episode: 222, reward: -116.26, average_reward: -188.35724918686196 \n",
      "episode: 223, reward: -240.16, average_reward: -200.09878992950297 \n",
      "episode: 224, reward: -119.13, average_reward: -177.48854231041182 \n",
      "episode: 225, reward: -114.44, average_reward: -165.24098877809647 \n",
      "episode: 226, reward: -123.61, average_reward: -143.55599779894663 \n",
      "episode: 227, reward: -123.54, average_reward: -144.20600939045028 \n",
      "episode: 228, reward: -116.78, average_reward: -131.78142604602027 \n",
      "episode: 229, reward: -2.4, average_reward: -120.29973471850414 \n",
      "episode: 230, reward: -120.92, average_reward: -120.40331008609515 \n",
      "episode: 231, reward: -221.59, average_reward: -129.88249912137817 \n",
      "episode: 232, reward: -0.84, average_reward: -118.34043311717289 \n",
      "episode: 233, reward: -126.54, average_reward: -106.97877811618187 \n",
      "episode: 234, reward: -2.15, average_reward: -95.28111853277528 \n",
      "episode: 235, reward: -0.94, average_reward: -83.93077738222179 \n",
      "episode: 236, reward: -114.82, average_reward: -83.0520845700301 \n",
      "episode: 237, reward: -119.82, average_reward: -82.68062394228112 \n",
      "episode: 238, reward: -238.71, average_reward: -94.87393748933542 \n",
      "episode: 239, reward: -0.09, average_reward: -94.64270173921761 \n",
      "episode: 240, reward: -119.59, average_reward: -94.51002081516665 \n",
      "episode: 241, reward: -118.7, average_reward: -84.22097782638167 \n",
      "episode: 242, reward: -119.18, average_reward: -96.05504267344898 \n",
      "episode: 243, reward: -122.15, average_reward: -95.61611858559677 \n",
      "episode: 244, reward: -125.47, average_reward: -107.94833143673164 \n",
      "episode: 245, reward: -243.68, average_reward: -132.22214117746626 \n",
      "episode: 246, reward: -129.9, average_reward: -133.73023193914526 \n",
      "episode: 247, reward: -127.6, average_reward: -134.5077639580328 \n",
      "episode: 248, reward: -128.39, average_reward: -123.47546096377141 \n",
      "episode: 249, reward: -125.35, average_reward: -136.00201401601564 \n",
      "episode: 250, reward: -128.86, average_reward: -136.92844272742735 \n",
      "episode: 251, reward: -130.1, average_reward: -138.06809034555798 \n",
      "episode: 252, reward: -128.1, average_reward: -138.96003270679662 \n",
      "episode: 253, reward: -131.08, average_reward: -139.85332494633093 \n",
      "episode: 254, reward: -257.94, average_reward: -153.1001124396326 \n",
      "episode: 255, reward: -253.21, average_reward: -154.05334278758843 \n",
      "episode: 256, reward: -12.4, average_reward: -142.30306000989873 \n",
      "episode: 257, reward: -128.84, average_reward: -142.42717973882003 \n",
      "episode: 258, reward: -265.29, average_reward: -156.11740122509818 \n",
      "episode: 259, reward: -135.89, average_reward: -157.17132111269981 \n",
      "episode: 260, reward: -350.57, average_reward: -179.34268528226858 \n",
      "episode: 261, reward: -135.0, average_reward: -179.8326826274842 \n",
      "episode: 262, reward: -132.63, average_reward: -180.28574655875 \n",
      "episode: 263, reward: -247.86, average_reward: -191.9631103517776 \n",
      "episode: 264, reward: -246.94, average_reward: -190.86341397390817 \n",
      "episode: 265, reward: -126.43, average_reward: -178.1860203312168 \n",
      "episode: 266, reward: -127.07, average_reward: -189.65319687301724 \n",
      "episode: 267, reward: -125.23, average_reward: -189.29289443554657 \n",
      "episode: 268, reward: -120.71, average_reward: -174.83407875965108 \n",
      "episode: 269, reward: -249.96, average_reward: -186.2402665976561 \n",
      "episode: 270, reward: -128.5, average_reward: -164.0326131309353 \n",
      "episode: 271, reward: -4.33, average_reward: -150.96593730094747 \n",
      "episode: 272, reward: -121.0, average_reward: -149.80219318043237 \n",
      "episode: 273, reward: -116.57, average_reward: -136.67403410161245 \n",
      "episode: 274, reward: -129.44, average_reward: -124.92372818450966 \n",
      "episode: 275, reward: -123.82, average_reward: -124.66261336641469 \n",
      "episode: 276, reward: -117.59, average_reward: -123.71445190727202 \n",
      "episode: 277, reward: -237.99, average_reward: -134.990050296622 \n",
      "episode: 278, reward: -318.74, average_reward: -154.7934350046971 \n",
      "episode: 279, reward: -115.56, average_reward: -141.35420177628052 \n",
      "episode: 280, reward: -117.71, average_reward: -140.27535767482638 \n",
      "episode: 281, reward: -229.89, average_reward: -162.83160926587723 \n",
      "episode: 282, reward: -242.01, average_reward: -174.9334615499426 \n",
      "episode: 283, reward: -127.84, average_reward: -176.06038151691996 \n",
      "episode: 284, reward: -240.36, average_reward: -187.15214606032913 \n",
      "episode: 285, reward: -128.66, average_reward: -187.63544531536508 \n",
      "episode: 286, reward: -239.86, average_reward: -199.8622994392646 \n",
      "episode: 287, reward: -126.68, average_reward: -188.7314515416445 \n",
      "episode: 288, reward: -5.36, average_reward: -157.39316319510922 \n",
      "episode: 289, reward: -123.23, average_reward: -158.1594005706012 \n",
      "episode: 290, reward: -251.25, average_reward: -171.51374769801944 \n",
      "episode: 291, reward: -243.34, average_reward: -172.8585269130728 \n",
      "episode: 292, reward: -127.82, average_reward: -161.43911367594245 \n",
      "episode: 293, reward: -10.29, average_reward: -149.6842088212692 \n",
      "episode: 294, reward: -131.74, average_reward: -138.82245157957738 \n",
      "episode: 295, reward: -128.58, average_reward: -138.81449907582007 \n",
      "episode: 296, reward: -8.57, average_reward: -115.68551567259806 \n",
      "episode: 297, reward: -247.86, average_reward: -127.80353218330015 \n",
      "episode: 298, reward: -8.18, average_reward: -128.0863343710299 \n",
      "episode: 299, reward: -128.39, average_reward: -128.6023581199257 \n",
      "episode: 300, reward: -238.52, average_reward: -127.32960306132591 \n",
      "episode: 301, reward: -250.17, average_reward: -128.01273763658924 \n",
      "episode: 302, reward: -124.27, average_reward: -127.65761872086861 \n",
      "episode: 303, reward: -242.96, average_reward: -150.9240695097878 \n",
      "episode: 304, reward: -11.21, average_reward: -138.87108102969438 \n",
      "episode: 305, reward: -125.7, average_reward: -138.58317400649102 \n",
      "episode: 306, reward: -130.49, average_reward: -150.7753265865118 \n",
      "episode: 307, reward: -258.1, average_reward: -151.79897262409642 \n",
      "episode: 308, reward: -125.81, average_reward: -163.5616985142696 \n",
      "episode: 309, reward: -368.77, average_reward: -187.60032653194634 \n",
      "episode: 310, reward: -125.84, average_reward: -176.33238286332067 \n",
      "episode: 311, reward: -131.54, average_reward: -164.4693933977221 \n",
      "episode: 312, reward: -245.08, average_reward: -176.550447989314 \n",
      "episode: 313, reward: -13.21, average_reward: -153.57524959761673 \n",
      "episode: 314, reward: -16.55, average_reward: -154.10909133205632 \n",
      "episode: 315, reward: -319.61, average_reward: -173.50074253441687 \n",
      "episode: 316, reward: -243.26, average_reward: -184.7773485732928 \n",
      "episode: 317, reward: -14.2, average_reward: -160.38755668122113 \n",
      "episode: 318, reward: -135.96, average_reward: -161.40239286580632 \n",
      "episode: 319, reward: -127.01, average_reward: -137.22625611130917 \n",
      "episode: 320, reward: -11.65, average_reward: -125.80705833118641 \n",
      "episode: 321, reward: -360.48, average_reward: -148.7011564686788 \n",
      "episode: 322, reward: -269.99, average_reward: -151.1926236559424 \n",
      "episode: 323, reward: -361.51, average_reward: -186.0228739386849 \n",
      "episode: 324, reward: -124.63, average_reward: -196.83086081926945 \n",
      "episode: 325, reward: -10.45, average_reward: -165.9145843139096 \n",
      "episode: 326, reward: -120.77, average_reward: -153.66584192499428 \n",
      "episode: 327, reward: -237.88, average_reward: -176.03353197916545 \n",
      "episode: 328, reward: -369.79, average_reward: -199.41616045587716 \n",
      "episode: 329, reward: -119.68, average_reward: -198.68260144541213 \n",
      "episode: 330, reward: -129.22, average_reward: -210.43944547315695 \n",
      "episode: 331, reward: -245.57, average_reward: -198.94841058614537 \n",
      "episode: 332, reward: -127.81, average_reward: -184.72954997481844 \n",
      "episode: 333, reward: -125.19, average_reward: -161.0973850511431 \n",
      "episode: 334, reward: -124.17, average_reward: -161.05141991443523 \n",
      "episode: 335, reward: -121.39, average_reward: -172.14529800861592 \n",
      "episode: 336, reward: -2.92, average_reward: -160.36065287021893 \n",
      "episode: 337, reward: -128.09, average_reward: -149.38172810337053 \n",
      "episode: 338, reward: -238.53, average_reward: -136.25655233318633 \n",
      "episode: 339, reward: -3.49, average_reward: -124.63789141068739 \n",
      "episode: 340, reward: -4.12, average_reward: -112.12808326602158 \n",
      "episode: 341, reward: -346.53, average_reward: -122.22363803141943 \n",
      "episode: 342, reward: -240.47, average_reward: -133.4898651387271 \n",
      "episode: 343, reward: -3.92, average_reward: -121.36339612420667 \n",
      "episode: 344, reward: -6.98, average_reward: -109.6445489136942 \n",
      "episode: 345, reward: -4.06, average_reward: -97.91131494944405 \n",
      "episode: 346, reward: -119.15, average_reward: -109.53356058924803 \n",
      "episode: 347, reward: -117.81, average_reward: -108.50605332672679 \n",
      "episode: 348, reward: -239.63, average_reward: -108.61546653073647 \n",
      "episode: 349, reward: -4.75, average_reward: -108.74185295620676 \n",
      "episode: 350, reward: -119.25, average_reward: -120.25450627756747 \n",
      "episode: 351, reward: -226.47, average_reward: -108.24875280214516 \n",
      "episode: 352, reward: -130.22, average_reward: -97.2237431912192 \n",
      "episode: 353, reward: -123.81, average_reward: -109.21271473125694 \n",
      "episode: 354, reward: -131.43, average_reward: -121.65770628538412 \n",
      "episode: 355, reward: -244.37, average_reward: -145.68909025666426 \n",
      "episode: 356, reward: -253.24, average_reward: -159.09829291494307 \n",
      "episode: 357, reward: -124.97, average_reward: -159.81416355892776 \n",
      "episode: 358, reward: -121.25, average_reward: -147.97629012749172 \n",
      "episode: 359, reward: -247.1, average_reward: -172.21066027034573 \n",
      "episode: 360, reward: -240.43, average_reward: -184.3283838909593 \n",
      "episode: 361, reward: -287.42, average_reward: -190.42338144869763 \n",
      "episode: 362, reward: -237.21, average_reward: -201.12297253673762 \n",
      "episode: 363, reward: -130.35, average_reward: -201.7762393221447 \n",
      "episode: 364, reward: -126.26, average_reward: -201.2591617273088 \n",
      "episode: 365, reward: -131.71, average_reward: -189.99267541000683 \n",
      "episode: 366, reward: -228.16, average_reward: -187.484719509452 \n",
      "episode: 367, reward: -127.41, average_reward: -187.72871808759635 \n",
      "episode: 368, reward: -122.99, average_reward: -187.9028179548037 \n",
      "episode: 369, reward: -230.64, average_reward: -186.25699194947126 \n",
      "episode: 370, reward: -255.05, average_reward: -187.71934212928727 \n",
      "episode: 371, reward: -381.26, average_reward: -197.10332158507612 \n",
      "episode: 372, reward: -244.29, average_reward: -197.81085624584415 \n",
      "episode: 373, reward: -125.22, average_reward: -197.29830953100097 \n",
      "episode: 374, reward: -121.32, average_reward: -196.80476091720502 \n",
      "episode: 375, reward: -247.14, average_reward: -208.34833419561792 \n",
      "episode: 376, reward: -124.54, average_reward: -197.9864503912241 \n",
      "episode: 377, reward: -257.43, average_reward: -210.9879994952872 \n",
      "episode: 378, reward: -124.84, average_reward: -211.1733794748502 \n",
      "episode: 379, reward: -248.6, average_reward: -212.96916248139928 \n",
      "episode: 380, reward: -14.0, average_reward: -188.86450205909566 \n",
      "episode: 381, reward: -135.74, average_reward: -164.31243650604569 \n",
      "episode: 382, reward: -132.12, average_reward: -153.0951932902313 \n",
      "episode: 383, reward: -244.84, average_reward: -165.05686924366495 \n",
      "episode: 384, reward: -130.69, average_reward: -165.99300473909253 \n",
      "episode: 385, reward: -136.94, average_reward: -154.97244064921435 \n",
      "episode: 386, reward: -139.88, average_reward: -156.50613953638418 \n",
      "episode: 387, reward: -133.48, average_reward: -144.1117460059965 \n",
      "episode: 388, reward: -129.06, average_reward: -144.5329131367768 \n",
      "episode: 389, reward: -256.91, average_reward: -145.3644423936904 \n",
      "episode: 390, reward: -127.81, average_reward: -156.74547495919853 \n",
      "episode: 391, reward: -243.93, average_reward: -167.56449621014556 \n",
      "episode: 392, reward: -133.99, average_reward: -167.75153938852534 \n",
      "episode: 393, reward: -265.55, average_reward: -169.82298966395823 \n",
      "episode: 394, reward: -139.68, average_reward: -170.72199595078263 \n",
      "episode: 395, reward: -130.51, average_reward: -170.07881974987217 \n",
      "episode: 396, reward: -244.26, average_reward: -180.51745678361706 \n",
      "episode: 397, reward: -130.81, average_reward: -180.24990791830598 \n",
      "episode: 398, reward: -256.03, average_reward: -192.94724863610998 \n",
      "episode: 399, reward: -18.77, average_reward: -169.13321805365138 \n",
      "episode: 400, reward: -253.93, average_reward: -181.7452922722094 \n",
      "episode: 401, reward: -18.51, average_reward: -159.2036934502669 \n",
      "episode: 402, reward: -132.35, average_reward: -159.04030307638655 \n",
      "episode: 403, reward: -269.75, average_reward: -159.46007699604525 \n",
      "episode: 404, reward: -142.36, average_reward: -159.72869374535293 \n",
      "episode: 405, reward: -19.06, average_reward: -148.58368819296982 \n",
      "episode: 406, reward: -21.42, average_reward: -126.29901827852886 \n",
      "episode: 407, reward: -19.11, average_reward: -115.12962744455376 \n",
      "episode: 408, reward: -129.51, average_reward: -102.47789293274965 \n",
      "episode: 409, reward: -127.41, average_reward: -113.34179885119724 \n",
      "episode: 410, reward: -249.24, average_reward: -112.87233679629614 \n",
      "episode: 411, reward: -342.53, average_reward: -145.27363536297696 \n",
      "episode: 412, reward: -354.39, average_reward: -167.4770079570331 \n",
      "episode: 413, reward: -136.43, average_reward: -154.14474504507865 \n",
      "episode: 414, reward: -138.55, average_reward: -153.76393180392597 \n",
      "episode: 415, reward: -125.01, average_reward: -164.3597449387449 \n",
      "episode: 416, reward: -256.36, average_reward: -187.85369008655735 \n",
      "episode: 417, reward: -125.78, average_reward: -198.5197645787919 \n",
      "episode: 418, reward: -126.06, average_reward: -198.1749548916501 \n",
      "episode: 419, reward: -130.54, average_reward: -198.48814154837223 \n",
      "episode: 420, reward: -130.28, average_reward: -186.5919980369305 \n",
      "episode: 421, reward: -129.44, average_reward: -165.2838370732922 \n",
      "episode: 422, reward: -130.41, average_reward: -142.88614082159683 \n",
      "episode: 423, reward: -135.63, average_reward: -142.8069374158647 \n",
      "episode: 424, reward: -136.21, average_reward: -142.57228148382845 \n",
      "episode: 425, reward: -239.38, average_reward: -154.0090457547951 \n",
      "episode: 426, reward: -333.54, average_reward: -161.7274273043532 \n",
      "episode: 427, reward: -269.01, average_reward: -176.05127534690595 \n",
      "episode: 428, reward: -125.37, average_reward: -175.98219745633125 \n",
      "episode: 429, reward: -130.06, average_reward: -175.9338276263814 \n",
      "episode: 430, reward: -247.83, average_reward: -187.68948294272178 \n",
      "episode: 431, reward: -124.79, average_reward: -187.22393113253753 \n",
      "episode: 432, reward: -134.49, average_reward: -187.63233226733007 \n",
      "episode: 433, reward: -134.43, average_reward: -187.51155466391717 \n",
      "episode: 434, reward: -246.18, average_reward: -198.50879359544314 \n",
      "episode: 435, reward: -130.04, average_reward: -187.5749442490167 \n",
      "episode: 436, reward: -126.47, average_reward: -166.86834498276124 \n",
      "episode: 437, reward: -135.37, average_reward: -153.50390113449754 \n",
      "episode: 438, reward: -123.45, average_reward: -153.31200285804857 \n",
      "episode: 439, reward: -288.04, average_reward: -169.1097431159694 \n",
      "episode: 440, reward: -357.02, average_reward: -180.02800916357734 \n",
      "episode: 441, reward: -121.62, average_reward: -179.71103386651112 \n",
      "episode: 442, reward: -237.83, average_reward: -190.04478732654846 \n",
      "episode: 443, reward: -132.54, average_reward: -189.8556653566223 \n",
      "episode: 444, reward: -129.89, average_reward: -178.22635948199257 \n",
      "episode: 445, reward: -130.13, average_reward: -178.23477888304117 \n",
      "episode: 446, reward: -124.38, average_reward: -178.02512145057932 \n",
      "episode: 447, reward: -129.59, average_reward: -177.44728077599592 \n",
      "episode: 448, reward: -122.33, average_reward: -177.33443005004196 \n",
      "episode: 449, reward: -128.02, average_reward: -161.33281742247118 \n",
      "episode: 450, reward: -253.3, average_reward: -150.9608552654757 \n",
      "episode: 451, reward: -118.73, average_reward: -150.67205113468378 \n",
      "episode: 452, reward: -134.03, average_reward: -140.29205343857691 \n",
      "episode: 453, reward: -130.84, average_reward: -140.12277033261228 \n",
      "episode: 454, reward: -133.32, average_reward: -140.4656558193644 \n",
      "episode: 455, reward: -127.63, average_reward: -140.21602595396064 \n",
      "episode: 456, reward: -237.37, average_reward: -151.51516691508968 \n",
      "episode: 457, reward: -352.75, average_reward: -173.83106058678084 \n",
      "episode: 458, reward: -339.52, average_reward: -195.55012473810672 \n",
      "episode: 459, reward: -247.36, average_reward: -207.4845166095025 \n",
      "episode: 460, reward: -236.07, average_reward: -205.76208955749675 \n",
      "episode: 461, reward: -237.3, average_reward: -217.61951049638577 \n",
      "episode: 462, reward: -232.2, average_reward: -227.43642634065196 \n",
      "episode: 463, reward: -4.52, average_reward: -214.80393580888253 \n",
      "episode: 464, reward: -244.29, average_reward: -225.90132688863704 \n",
      "episode: 465, reward: -236.18, average_reward: -236.7563268527095 \n",
      "episode: 466, reward: -128.89, average_reward: -225.90805344016854 \n",
      "episode: 467, reward: -337.85, average_reward: -224.417611166422 \n",
      "episode: 468, reward: -116.88, average_reward: -202.15400965017733 \n",
      "episode: 469, reward: -2.46, average_reward: -177.66373786067695 \n",
      "episode: 470, reward: -241.64, average_reward: -178.22001844497336 \n",
      "episode: 471, reward: -128.88, average_reward: -167.37705573428644 \n",
      "episode: 472, reward: -244.01, average_reward: -168.55825974659354 \n",
      "episode: 473, reward: -117.34, average_reward: -179.84043233704074 \n",
      "episode: 474, reward: -120.0, average_reward: -167.41158458291653 \n",
      "episode: 475, reward: -246.98, average_reward: -168.4916571165878 \n",
      "episode: 476, reward: -121.52, average_reward: -167.75480506724634 \n",
      "episode: 477, reward: -3.19, average_reward: -134.2892176313387 \n",
      "episode: 478, reward: -130.18, average_reward: -135.61924903868996 \n",
      "episode: 479, reward: -1.6, average_reward: -135.53319710617933 \n",
      "episode: 480, reward: -127.29, average_reward: -124.09836952437733 \n",
      "episode: 481, reward: -251.09, average_reward: -136.31982698816606 \n",
      "episode: 482, reward: -230.63, average_reward: -134.98132119661165 \n",
      "episode: 483, reward: -117.7, average_reward: -135.01754240964914 \n",
      "episode: 484, reward: -1.61, average_reward: -123.17894288264786 \n",
      "episode: 485, reward: -116.64, average_reward: -110.1444726103878 \n",
      "episode: 486, reward: -347.67, average_reward: -132.75994051567744 \n",
      "episode: 487, reward: -232.74, average_reward: -155.71495052906226 \n",
      "episode: 488, reward: -119.46, average_reward: -154.64247588920904 \n",
      "episode: 489, reward: -126.23, average_reward: -167.10599410522173 \n",
      "episode: 490, reward: -115.12, average_reward: -165.88941665407688 \n",
      "episode: 491, reward: -232.27, average_reward: -164.00731729754122 \n",
      "episode: 492, reward: -359.66, average_reward: -176.9106104877844 \n",
      "episode: 493, reward: -120.62, average_reward: -177.20252746017167 \n",
      "episode: 494, reward: -117.34, average_reward: -188.77550419627096 \n",
      "episode: 495, reward: -232.91, average_reward: -200.40308444461243 \n",
      "episode: 496, reward: -124.17, average_reward: -178.05286429341328 \n",
      "episode: 497, reward: -128.47, average_reward: -167.62615551106379 \n",
      "episode: 498, reward: -252.29, average_reward: -180.90908495714686 \n",
      "episode: 499, reward: -126.03, average_reward: -180.88876520519824 \n"
     ]
    }
   ],
   "source": [
    "# Define instances of the environment, DDPG agent and the OU noise.\n",
    "env   = gym.make( \"Pendulum-v1\" ) \n",
    "\n",
    "# Set the random seeds\n",
    "env.seed(              round( time.time( ) ) )\n",
    "env.action_space.seed( round( time.time( ) ) )\n",
    "torch.manual_seed(     round( time.time( ) ) )\n",
    "np.random.seed(        round( time.time( ) ) )\n",
    "\n",
    "# Get the dimension of states and actions, and also the \n",
    "# [WARNING] This is for environments where we assume the mean of action is 0. \n",
    "n_state    = env.observation_space.shape[ 0 ] \n",
    "n_action   = env.action_space.shape[ 0 ]\n",
    "max_action = float( env.action_space.high  )\n",
    "\n",
    "# Define the agent, noise and replay buffers\n",
    "agent         = TD3( n_state, n_action, max_action )\n",
    "replay_buffer = ReplayBuffer( n_state, n_action )\n",
    "\n",
    "# The number of \"batch\" that will be sampled from the replay buffer will be \"batch_size\" \n",
    "n_batch_size  = 256\n",
    "\n",
    "# Saving these values to plot the performance at the end.\n",
    "frames        = [ ]\n",
    "whole_rewards = [ ]\n",
    "\n",
    "# Flags for turning on or off the render.\n",
    "is_save_video = False\n",
    "is_save_model = False\n",
    "\n",
    "# For the pendulum model the best reward is 0, hence saving a -infinity value. \n",
    "best_model_val = -np.inf\n",
    "\n",
    "rewards       = [ ]\n",
    "avg_rewards   = [ ]\n",
    "\n",
    "for episode in range( 500 ):\n",
    "\n",
    "    # Initialize the gym environment and OU noise \n",
    "    state = env.reset()\n",
    "\n",
    "    # Initialize the episode's reward\n",
    "    episode_reward = 0\n",
    "    \n",
    "    # For pendulum v1 gym, a single simulation is maximum 200-steps long. \n",
    "    # [REF] https://github.com/openai/gym/blob/master/gym/envs/classic_control/pendulum.py\n",
    "    for step in range( 200 ):\n",
    "\n",
    "        # Get the action value from the deterministic policy Actor network.\n",
    "        action = agent.get_action( state )\n",
    "\n",
    "        if is_save_video : frames.append( env.render( mode = 'rgb_array' ) )\n",
    "\n",
    "        # Apply the OU noise on this action\n",
    "\n",
    "        # Run a single step of simulation\n",
    "        new_state, reward, done, _ = env.step( action )  \n",
    "\n",
    "        # Add this to our replay buffer, note that push simply generates the tuple and add \n",
    "        replay_buffer.add( state, action, reward, new_state, done )\n",
    "        \n",
    "        # Once the agent memory is full, then update the policy via replay buffer.\n",
    "        if replay_buffer.current_size > n_batch_size: agent.update( replay_buffer, batch_size = n_batch_size )        \n",
    "        \n",
    "        # Update the state and reward value \n",
    "        state = new_state\n",
    "        episode_reward += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    if best_model_val <= episode_reward:\n",
    "        best_model_val = episode_reward \n",
    "\n",
    "        # If this policy has a good result, save it \n",
    "        if is_save_model: agent.save( \"../models/DDPG_best_model\" ) \n",
    "\n",
    "    # Once a single simulation is done, append the values that will be plotted later\n",
    "    rewards.append( episode_reward )\n",
    "    avg_rewards.append( np.mean( rewards[ -10 : ] ) )\n",
    "\n",
    "    sys.stdout.write(\"episode: {}, reward: {}, average_reward: {} \\n\".format( episode, np.round( episode_reward, decimals = 2 ), avg_rewards[ -1 ] ) ) \n",
    "\n",
    "whole_rewards.append(  rewards  )\n",
    "\n",
    "env.close( )\n",
    "\n",
    "if is_save_video:\n",
    "    clip = mpy.ImageSequenceClip( frames, fps = 30 )\n",
    "    clip.write_gif( \"../videos/DDPG.gif\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.plot( rewards     )\n",
    "plt.plot( avg_rewards )\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "742fb12a3d29bb1ab201ca06dfc1cb9996440041728c355377b69362e9fdf7ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
