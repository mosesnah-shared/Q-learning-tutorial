{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding PyTorch\n",
    "\n",
    "We use this notebook to study about the structure of PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "import time\n",
    "import numpy as np  \n",
    "\n",
    "import torch  \n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim         as optim\n",
    "from   torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot   as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "layer1 = nn.Linear( 1, 5 )\n",
    "\n",
    "tmp = torch.from_numpy( np.array( [1,4,5,6,1 ] ) ).float( ).unsqueeze( 0 )\n",
    "print( tmp.shape )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Network\n",
    "We use a three layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ExampleNetwork( nn.Module ):\n",
    "    def __init__( self, num_inputs, num_outputs, hidden_size, learning_rate = 3e-4 ):\n",
    "        super( ExampleNetwork , self).__init__()\n",
    "\n",
    "        self.num_actions = num_inputs\n",
    "        self.linear1     = nn.Linear( num_inputs, hidden_size  )\n",
    "        self.linear2     = nn.Linear( hidden_size, num_inputs )\n",
    "\n",
    "        # Using the ADAM optimizer. \n",
    "        self.optimizer   = optim.Adam( self.parameters( ), lr = learning_rate )\n",
    "\n",
    "    def forward( self, state ):\n",
    "        x = F.relu( self.linear1( state ) )\n",
    "        x = F.softmax( self.linear2( x ), dim = 1 )\n",
    "        return x \n",
    "    \n",
    "    def get_action( self, state ):\n",
    "        state = torch.from_numpy( state ).float( ).unsqueeze( 0 ) # Makes a 1 x ns tensor.\n",
    "\n",
    "        # Forward the neural network and return the prbability distribution function\n",
    "        probs = self.forward( Variable( state ) )\n",
    "\n",
    "        # Choosing the action based on the output policy\n",
    "        highest_prob_action = np.random.choice( self.num_actions, p = np.squeeze( probs.detach( ).numpy( ) ) )\n",
    "\n",
    "        # The log-value of the probability just for the sake of policy gradient\n",
    "        log_prob = torch.log( probs.squeeze( 0 )[ highest_prob_action ] )\n",
    "        \n",
    "        return highest_prob_action, log_prob\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "742fb12a3d29bb1ab201ca06dfc1cb9996440041728c355377b69362e9fdf7ce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
